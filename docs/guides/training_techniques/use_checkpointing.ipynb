{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e9134fa",
   "metadata": {},
   "source": [
    "# Save and load checkpoints\n",
    "\n",
    "This guide demonstrates how to save and load Flax checkpoints with [Orbax](https://github.com/google/orbax).\n",
    "\n",
    "Orbax provides a variety of features for saving and loading model data, which you will learn about in this doc:\n",
    "\n",
    "*  Support for various array types and storage formats\n",
    "*  Asynchronous saving to reduce training wait time\n",
    "*  Versioning and automatic bookkeeping of past checkpoints\n",
    "*  Flexible [`transformations`](https://github.com/google/orbax/blob/main/docs/checkpoint.md#transformations) to tweak and load old checkpoints\n",
    "*  [`jax.sharding`](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html)-based API to save and load in multi-host scenarios\n",
    "\n",
    "If you need to learn more about `orbax.checkpoint`, refer to the [Orbax docs](https://github.com/google/orbax/blob/main/docs/checkpoint.md).\n",
    "\n",
    "---\n",
    "**_Deprecation of legacy Flax checkpoint APIs:_** \n",
    "\n",
    "Flax's legacy `flax.training.checkpoints` API is deprecated in favor of [Orbax](https://github.com/google/orbax). \n",
    "\n",
    "If you have legacy `flax.training.checkpoints` code in your project, consider the following options:\n",
    "\n",
    "   * **Migrating your code to Orbax (Recommended)**: Migrate your API calls to `orbax.checkpoint` API by following this [migration guide](https://flax.readthedocs.io/en/latest/guides/converting_and_upgrading/orbax_upgrade_guide.html).\n",
    "\n",
    "   * **Automatically use the Orbax backend**: Add `flax.config.update('flax_use_orbax_checkpointing', True)` to your project, which will let your `flax.training.checkpoints` calls automatically use the Orbax backend to save your checkpoints.\n",
    "\n",
    "     * Visit [Orbax-as-backend troubleshooting section](https://flax.readthedocs.io/en/latest/guides/training_techniques/use_checkpointing.html#orbax-as-backend-troubleshooting) if you meet any issue in the automatic migration.\n",
    "\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "Install/upgrade Flax and [Orbax](https://github.com/google/orbax). For JAX installation with GPU/TPU support, visit [this section on GitHub](https://github.com/google/jax#installation)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "-icO30rwmKYj",
   "metadata": {},
   "source": [
    "Note: Before running `import jax`, create eight fake devices to mimic a [multi-host environment](https://jax.readthedocs.io/en/latest/jax-101/06-parallelism.html?#aside-hosts-and-devices-in-jax) in this notebook. Note that the order of imports is important here. The `os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'` command works only with the CPU backend, which means it won't work with GPU/TPU acceleration on if you're running this notebook in Google Colab. If you are already running the code on multiple devices (for example, in a 4x2 TPU environment), you can skip running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ArKLnsyGRxGv",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SJT9DTxTytjn",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tensorflow library not found, tensorflow.io.gfile operations will use native shim calls. GCS paths (i.e. 'gs://...') cannot be accessed.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional, Any\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "from jax import random, numpy as jnp\n",
    "\n",
    "import flax\n",
    "from flax import linen as nn\n",
    "from flax.training import checkpoints, train_state\n",
    "from flax import struct, serialization\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd6db30",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = '/tmp/flax_ckpt'\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)  # Remove any existing checkpoints from the last notebook run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d434cd",
   "metadata": {},
   "source": [
    "## Save checkpoints\n",
    "\n",
    "In Orbax and Flax, you can save and load any given JAX [pytree](https://jax.readthedocs.io/en/latest/pytrees.html). This includes not only typical Python and NumPy containers, but also customized classes extended from [`flax.struct.dataclass`](https://flax.readthedocs.io/en/latest/api_reference/flax.struct.html#flax.struct.dataclass). That means you can store almost any data generated — not only your model parameters, but any arrays/dictionaries, metadata/configs, and so on.\n",
    "\n",
    "First, create a pytree with many data structures and containers, and play with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56dec3f6",
   "metadata": {
    "outputId": "f1856d96-1961-48ed-bb7c-cb63fbaa7567"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': TrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': Array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': Array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "        [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "        [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "        [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "        [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x30df92b00>, update=<function chain.<locals>.update_fn at 0x30df92b90>), opt_state=(EmptyState(), EmptyState())),\n",
       " 'config': {'dimensions': array([5, 3])},\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simple model with one linear layer.\n",
    "key1, key2 = random.split(random.key(0))\n",
    "x1 = random.normal(key1, (5,))      # A simple JAX array.\n",
    "model = nn.Dense(features=3)\n",
    "variables = model.init(key2, x1)\n",
    "\n",
    "# Flax's TrainState is a pytree dataclass and is supported in checkpointing.\n",
    "# Define your class with `@flax.struct.dataclass` decorator to make it compatible.\n",
    "tx = optax.sgd(learning_rate=0.001)      # An Optax SGD optimizer.\n",
    "state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=variables['params'],\n",
    "    tx=tx)\n",
    "# Perform a simple gradient update similar to the one during a normal training workflow.\n",
    "state = state.apply_gradients(grads=jax.tree_map(jnp.ones_like, state.params))\n",
    "\n",
    "# Some arbitrary nested pytree with a dictionary and a NumPy array.\n",
    "config = {'dimensions': np.array([5, 3])}\n",
    "\n",
    "# Bundle everything together.\n",
    "ckpt = {'model': state, 'config': config, 'data': [x1]}\n",
    "ckpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c715b95",
   "metadata": {},
   "source": [
    "### With Orbax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc59dfa",
   "metadata": {},
   "source": [
    "Save the checkpoint with `orbax.checkpoint.PyTreeCheckpointer`, directly to the `tmp/orbax/single_save` directory.\n",
    "\n",
    "Note: An optional `save_args` is provided. This is recommended for performance speedups, as it bundles smaller arrays in your pytree to a single large file instead of multiple smaller files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b12da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n"
     ]
    }
   ],
   "source": [
    "orbax_checkpointer = ocp.StandardCheckpointer()\n",
    "orbax_checkpointer.save('/tmp/flax_ckpt/orbax/single_save', ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d4de1a",
   "metadata": {},
   "source": [
    "Next, to use versioning and automatic bookkeeping features, you need to wrap `orbax.checkpoint.CheckpointManager` over `orbax.checkpoint.PyTreeCheckpointer`. \n",
    "\n",
    "In addition, provide `orbax.checkpoint.CheckpointManagerOptions` that customizes your needs, such as how often and on what criteria you prefer old checkpoints be deleted. See [documentation](https://github.com/google/orbax/blob/main/docs/checkpoint.md#checkpointmanager) for a full list of options offered.\n",
    "\n",
    "`orbax.checkpoint.CheckpointManager` should be placed at the top-level outside your training steps to manage your saves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3686ea5",
   "metadata": {
    "outputId": "b7132933-566d-440d-c34e-c5468d87cbdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['4', '3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = ocp.CheckpointManagerOptions(max_to_keep=2, create=True)\n",
    "checkpoint_manager = ocp.CheckpointManager(\n",
    "    '/tmp/flax_ckpt/orbax/managed', options=options, \n",
    "    item_handlers=ocp.StandardCheckpointHandler())\n",
    "\n",
    "# Inside a training loop\n",
    "for step in range(5):\n",
    "    # ... do your training\n",
    "    checkpoint_manager.save(step, ckpt)\n",
    "\n",
    "checkpoint_manager.wait_until_finished()\n",
    "os.listdir('/tmp/flax_ckpt/orbax/managed')  # Because max_to_keep=2, only step 3 and 4 are retained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b658bd1",
   "metadata": {},
   "source": [
    "## Restore checkpoints\n",
    "\n",
    "### With Orbax\n",
    "\n",
    "In Orbax, call `.restore()` for either `orbax.checkpoint.PyTreeCheckpointer` or `orbax.checkpoint.CheckpointManager` to restore your checkpoint in the raw pytree format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a807a9c1",
   "metadata": {
    "outputId": "b4af1ef4-f22f-459b-bdca-2e6bfa16c08b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'dimensions': array([5, 3])},\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)],\n",
       " 'model': {'opt_state': [None, None],\n",
       "  'params': {'bias': Array([-0.001, -0.001, -0.001], dtype=float32),\n",
       "   'kernel': Array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "          [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "          [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "          [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "          [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)},\n",
       "  'step': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_restored = orbax_checkpointer.restore('/tmp/flax_ckpt/orbax/single_save')\n",
    "raw_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c015a22",
   "metadata": {},
   "source": [
    "Note that the `step` number is required for `CheckpointManger`. You can also use `.latest_step()` to find the latest step available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "251d7085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'dimensions': array([5, 3])},\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)],\n",
       " 'model': {'opt_state': [None, None],\n",
       "  'params': {'bias': Array([-0.001, -0.001, -0.001], dtype=float32),\n",
       "   'kernel': Array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "          [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "          [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "          [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "          [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)},\n",
       "  'step': 1}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = checkpoint_manager.latest_step()  # step = 4\n",
    "checkpoint_manager.restore(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe3bc8",
   "metadata": {},
   "source": [
    "### With the legacy API\n",
    "\n",
    "This should only be used if you have a legacy Flax checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "150b20a0",
   "metadata": {
    "outputId": "85ffceca-f38d-46b8-e567-d9d38b7885f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'dimensions': array([5, 3])},\n",
       " 'data': {'0': array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],\n",
       "        dtype=float32)},\n",
       " 'model': {'opt_state': {'0': None, '1': None},\n",
       "  'params': {'bias': array([-0.001, -0.001, -0.001], dtype=float32),\n",
       "   'kernel': array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "          [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "          [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "          [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "          [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)},\n",
       "  'step': 1}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_restored = checkpoints.restore_checkpoint(ckpt_dir='/tmp/flax_ckpt/flax-checkpointing', target=None)\n",
    "raw_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987b981f",
   "metadata": {},
   "source": [
    "## Restore with custom dataclasses\n",
    "\n",
    "### With Orbax\n",
    "\n",
    "*  The pytrees restored in the previous examples are in the form of raw dictionaries. Original pytrees contain custom dataclasses like [`TrainState`](https://flax.readthedocs.io/en/latest/flip/1009-optimizer-api.html?#train-state) and `optax` states.\n",
    "*  This is because when restoring a pytree, the program does not yet know which structure it once belonged to.\n",
    "*  To resolve this, you should first provide an example pytree to let Orbax or Flax know exactly which structure to restore to.\n",
    "\n",
    "This section demonstrates how to set up any custom Flax dataclass explicitly, and have the same structure as a saved checkpoint.\n",
    "\n",
    "Note: Data that was a JAX NumPy array (`jnp.array`) format will be restored as a NumPy array (`numpy.array`). This would not affect your work because JAX will [automatically convert](https://jax.readthedocs.io/en/latest/jax-101/01-jax-basics.html) NumPy arrays to JAX arrays once the computation starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f42513",
   "metadata": {
    "outputId": "110c6b6e-fe42-4179-e5d8-6b92d355e11b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'dimensions': array([5, 3])},\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)],\n",
       " 'model': TrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "        [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "        [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "        [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "        [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x30df92b00>, update=<function chain.<locals>.update_fn at 0x30df92b90>), opt_state=(EmptyState(), EmptyState()))}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_state = train_state.TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=jax.tree_map(np.zeros_like, variables['params']),  # values of the tree leaf doesn't matter\n",
    "    tx=tx,\n",
    ")\n",
    "empty_config = {'dimensions': np.array([0, 0])}\n",
    "target = {'model': empty_state, 'config': empty_config, 'data': [jnp.zeros_like(x1)]}\n",
    "state_restored = orbax_checkpointer.restore('/tmp/flax_ckpt/orbax/single_save', item=target)\n",
    "state_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c18bc6",
   "metadata": {},
   "source": [
    "Alternatively, you can restore from Orbax `CheckpointManager` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a61e9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config': {'dimensions': array([5, 3])},\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)],\n",
       " 'model': TrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "        [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "        [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "        [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "        [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x30df92b00>, update=<function chain.<locals>.update_fn at 0x30df92b90>), opt_state=(EmptyState(), EmptyState()))}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_manager.restore(4, args=ocp.args.StandardRestore(target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27461ac8",
   "metadata": {},
   "source": [
    "It's often recommended to refactor out the process of initializing a checkpoint's structure (for example, a [`TrainState`](https://flax.readthedocs.io/en/latest/flip/1009-optimizer-api.html?#train-state)), so that saving/loading is easier and less error-prone. This is because functions and complex objects like `apply_fn` and `tx` (optimizer) cannot be serialized into the checkpoint file and must be initialized by code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "136a300a",
   "metadata": {},
   "source": [
    "## Restore when checkpoint structures differ\n",
    "\n",
    "During your development, your checkpoint structure will change when changing the model, adding/removing fields during tweaking, and so on.\n",
    "\n",
    "This section explains how to load old data to your new code.\n",
    "\n",
    "Below is  a simple example — a `CustomTrainState` extended from `flax.training.train_state.TrainState` that contains an extra field called `batch_stats`. When working on a real-world model, you may need this when applying [batch normalization](https://flax.readthedocs.io/en/latest/guides/training_techniques/batch_norm.html).\n",
    "\n",
    "Here, you store the new `CustomTrainState` as step 5, while step 4 contains the old/previous `TrainState`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be65d4af",
   "metadata": {
    "outputId": "4fe776f0-65f8-4fc4-d64a-990520b36dce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomTrainState(train_state.TrainState):\n",
    "    batch_stats: Any = None\n",
    "\n",
    "custom_state = CustomTrainState.create(\n",
    "    apply_fn=state.apply_fn,\n",
    "    params=state.params,\n",
    "    tx=state.tx,\n",
    "    batch_stats=np.arange(10),\n",
    ")\n",
    "\n",
    "custom_ckpt = {'model': custom_state, 'config': config, 'data': [x1]}\n",
    "# Use a custom state to read the old `TrainState` checkpoint.\n",
    "custom_target = {'model': custom_state, 'config': None, 'data': [jnp.zeros_like(x1)]}\n",
    "\n",
    "# Save it in Orbax.\n",
    "checkpoint_manager.save(5, custom_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379c2255",
   "metadata": {},
   "source": [
    "It is recommended to keep your checkpoints up-to-date with your pytree dataclass definitions. However, you might be forced to restore the checkpoints with incompatible reference objects at runtime. When this happens, the checkpoint restoration will try to respect the structure of the reference when given.\n",
    "\n",
    "Below are examples of a few common scenarios."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5fa9652",
   "metadata": {},
   "source": [
    "### Scenario 1: When a reference object is partial\n",
    "\n",
    "TODO: explain the default behavior and correct solution for partial loading. If transforms are required, showcase it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68828029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError when target state has an unmentioned field: \n",
      "Dict key mismatch; expected keys: ['batch_stats', 'opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32')), 'kernel': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32'))}, 'opt_state': [EmptyState(), EmptyState()]}.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dict key mismatch; expected keys: ['batch_stats', 'opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32')), 'kernel': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32'))}, 'opt_state': [EmptyState(), EmptyState()]}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValueError when target state has an unmentioned field: \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTreeRestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/checkpoint_manager.py:867\u001b[0m, in \u001b[0;36mCheckpointManager.restore\u001b[0;34m(self, step, items, restore_kwargs, directory, args)\u001b[0m\n\u001b[1;32m    864\u001b[0m     args \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(args_lib\u001b[38;5;241m.\u001b[39mComposite, args)\n\u001b[1;32m    866\u001b[0m restore_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_save_directory(step, directory)\n\u001b[0;32m--> 867\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_item:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m restored[DEFAULT_ITEM_NAME]\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/async_checkpointer.py:320\u001b[0m, in \u001b[0;36mAsyncCheckpointer.restore\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See superclass documentation.\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_until_finished()\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/checkpointer.py:166\u001b[0m, in \u001b[0;36mCheckpointer.restore\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestoring item from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, directory)\n\u001b[1;32m    165\u001b[0m ckpt_args \u001b[38;5;241m=\u001b[39m construct_checkpoint_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 166\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished restoring checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, directory)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restored\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/composite_checkpoint_handler.py:459\u001b[0m, in \u001b[0;36mCompositeCheckpointHandler.restore\u001b[0;34m(self, directory, args)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    458\u001b[0m   handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_set_handler(item_name, arg)\n\u001b[0;32m--> 459\u001b[0m   restored[item_name] \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompositeResults(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrestored)\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/standard_checkpoint_handler.py:165\u001b[0m, in \u001b[0;36mStandardCheckpointHandler.restore\u001b[0;34m(self, directory, item, args)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m   restore_args \u001b[38;5;241m=\u001b[39m checkpoint_utils\u001b[38;5;241m.\u001b[39mconstruct_restore_args(\n\u001b[1;32m    163\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata(directory)\n\u001b[1;32m    164\u001b[0m   )\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytree_checkpoint_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTreeRestoreArgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestore_args\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/pytree_checkpoint_handler.py:1069\u001b[0m, in \u001b[0;36mPyTreeCheckpointHandler.restore\u001b[0;34m(self, directory, item, restore_args, transforms, transforms_default_to_original, legacy_transform_fn, args)\u001b[0m\n\u001b[1;32m   1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m meta\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# If metadata file was missing in the checkpoint, we need to decide\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# restore_type based on RestoreArgs.\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m structure \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_maybe_set_default_restore_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_restore_args\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m restored_item \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_deserialize(structure, param_infos, checkpoint_restore_args)\n\u001b[1;32m   1075\u001b[0m )\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m legacy_transform_fn:\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/jax/_src/tree_util.py:311\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/jax/_src/tree_util.py:311\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Dict key mismatch; expected keys: ['batch_stats', 'opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32')), 'kernel': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('float32'))}, 'opt_state': [EmptyState(), EmptyState()]}."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    restored = checkpoint_manager.restore(5, args=ocp.args.PyTreeRestore(target))\n",
    "except ValueError as e:\n",
    "    print(f'ValueError when target state has an unmentioned field: ')\n",
    "    print(f'{e}')\n",
    "\n",
    "restored = checkpoint_manager.restore(\n",
    "    5, args=ocp.args.PyTreeRestore(target), \n",
    "    restore_kwargs=dict(transforms={'model': {'batch_stats': 0}}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c6822c6",
   "metadata": {},
   "source": [
    "### Scenario 2: When a checkpoint is partial\n",
    "\n",
    "On the other hand, if the reference object contains a value that is not available in the checkpoint, the checkpointing code will by default warn that some data is not compatible.\n",
    "\n",
    "To bypass the error, you need to pass an Orbax [`transform`](https://github.com/google/orbax/blob/main/docs/checkpoint.md#transformations) that teaches Orbax how to conform this checkpoint into the structure of the `custom_target`.\n",
    "\n",
    "In this case, pass a default `{}` that lets Orbax use values in the `custom_target` to fill in the blank. This allows you to restore an old checkpoint into a new data structure, the `CustomTrainState`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5d14c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError when target state has an unmentioned field: \n",
      "Dict key mismatch; expected keys: ['opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(3,)), 'kernel': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(5, 3))}, 'opt_state': [EmptyState(), EmptyState()], 'batch_stats': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('int64'))}.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dict key mismatch; expected keys: ['opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(3,)), 'kernel': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(5, 3))}, 'opt_state': [EmptyState(), EmptyState()], 'batch_stats': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('int64'))}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 4 is an original `TrainState`, without the `batch_stats`\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[43mcheckpoint_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTreeRestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcustom_target\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(restored[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m==\u001b[39m CustomTrainState\n\u001b[1;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_equal(restored[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_stats,\n\u001b[1;32m     11\u001b[0m                         custom_target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_stats)\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/checkpoint_manager.py:867\u001b[0m, in \u001b[0;36mCheckpointManager.restore\u001b[0;34m(self, step, items, restore_kwargs, directory, args)\u001b[0m\n\u001b[1;32m    864\u001b[0m     args \u001b[38;5;241m=\u001b[39m typing\u001b[38;5;241m.\u001b[39mcast(args_lib\u001b[38;5;241m.\u001b[39mComposite, args)\n\u001b[1;32m    866\u001b[0m restore_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_save_directory(step, directory)\n\u001b[0;32m--> 867\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_checkpointer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrestore_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_single_item:\n\u001b[1;32m    869\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m restored[DEFAULT_ITEM_NAME]\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/async_checkpointer.py:320\u001b[0m, in \u001b[0;36mAsyncCheckpointer.restore\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See superclass documentation.\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait_until_finished()\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/checkpointer.py:166\u001b[0m, in \u001b[0;36mCheckpointer.restore\u001b[0;34m(self, directory, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestoring item from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, directory)\n\u001b[1;32m    165\u001b[0m ckpt_args \u001b[38;5;241m=\u001b[39m construct_checkpoint_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handler, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 166\u001b[0m restored \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished restoring checkpoint from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, directory)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m restored\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/composite_checkpoint_handler.py:459\u001b[0m, in \u001b[0;36mCompositeCheckpointHandler.restore\u001b[0;34m(self, directory, args)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    458\u001b[0m   handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_or_set_handler(item_name, arg)\n\u001b[0;32m--> 459\u001b[0m   restored[item_name] \u001b[38;5;241m=\u001b[39m \u001b[43mhandler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_item_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompositeResults(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrestored)\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/standard_checkpoint_handler.py:165\u001b[0m, in \u001b[0;36mStandardCheckpointHandler.restore\u001b[0;34m(self, directory, item, args)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m   restore_args \u001b[38;5;241m=\u001b[39m checkpoint_utils\u001b[38;5;241m.\u001b[39mconstruct_restore_args(\n\u001b[1;32m    163\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata(directory)\n\u001b[1;32m    164\u001b[0m   )\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrestore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytree_checkpoint_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTreeRestoreArgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mitem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrestore_args\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/orbax/checkpoint/pytree_checkpoint_handler.py:1069\u001b[0m, in \u001b[0;36mPyTreeCheckpointHandler.restore\u001b[0;34m(self, directory, item, restore_args, transforms, transforms_default_to_original, legacy_transform_fn, args)\u001b[0m\n\u001b[1;32m   1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m meta\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;66;03m# If metadata file was missing in the checkpoint, we need to decide\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;66;03m# restore_type based on RestoreArgs.\u001b[39;00m\n\u001b[0;32m-> 1069\u001b[0m structure \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1070\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_maybe_set_default_restore_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_restore_args\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1073\u001b[0m restored_item \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1074\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_deserialize(structure, param_infos, checkpoint_restore_args)\n\u001b[1;32m   1075\u001b[0m )\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m legacy_transform_fn:\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/jax/_src/tree_util.py:311\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/jax/_src/tree_util.py:311\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 311\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Dict key mismatch; expected keys: ['opt_state', 'params', 'step']; dict: {'step': RestoreArgs(restore_type=<class 'int'>, dtype=None), 'params': {'bias': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(3,)), 'kernel': ArrayRestoreArgs(restore_type=<class 'jax.Array'>, dtype=dtype('float32'), mesh=None, mesh_axes=None, sharding=SingleDeviceSharding(device=CpuDevice(id=0)), global_shape=(5, 3))}, 'opt_state': [EmptyState(), EmptyState()], 'batch_stats': RestoreArgs(restore_type=<class 'numpy.ndarray'>, dtype=dtype('int64'))}."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    checkpoint_manager.restore(4, items=custom_target)\n",
    "except ValueError as e:\n",
    "    print(f'ValueError when target state has an unmentioned field: ')\n",
    "    print(f'{e}')\n",
    "\n",
    "# Step 4 is an original `TrainState`, without the `batch_stats`\n",
    "restored = checkpoint_manager.restore(4, args=ocp.args.PyTreeRestore(custom_target))\n",
    "assert type(restored['model']) == CustomTrainState\n",
    "np.testing.assert_equal(restored['model'].batch_stats,\n",
    "                        custom_target['model'].batch_stats)\n",
    "restored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4b0fd",
   "metadata": {},
   "source": [
    "##### With Orbax\n",
    "\n",
    "If you have already saved your checkpoints with the Orbax backend, you can use `orbax_transforms` to access this `transforms` argument in the Flax API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fd1e33",
   "metadata": {
    "outputId": "cdbb9247-d1eb-4458-aa83-8db0332af7cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024.\n",
      "WARNING:absl:The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': CustomTrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': Array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': Array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "        [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "        [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "        [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "        [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x30df92b00>, update=<function chain.<locals>.update_fn at 0x30df92b90>), opt_state=(EmptyState(), EmptyState()), batch_stats=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])),\n",
       " 'config': None,\n",
       " 'data': [Array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],      dtype=float32)]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save in the \"Flax-with-Orbax\" backend.\n",
    "flax.config.update('flax_use_orbax_checkpointing', True)\n",
    "checkpoints.save_checkpoint(ckpt_dir='/tmp/flax_ckpt/flax-checkpointing',\n",
    "                            target=ckpt,\n",
    "                            step=4,\n",
    "                            overwrite=True,\n",
    "                            keep=2)\n",
    "\n",
    "checkpoints.restore_checkpoint('/tmp/flax_ckpt/flax-checkpointing', target=custom_target, step=4,\n",
    "                               orbax_transforms={})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ef07c",
   "metadata": {},
   "source": [
    "##### With the legacy API\n",
    "\n",
    "Using the legacy `flax.training.checkpoints` API, similar things are doable too, but they are not as flexible as the [Orbax Transformations](https://github.com/google/orbax/blob/main/docs/checkpoint.md#transformations).\n",
    "\n",
    "You need to restore the checkpoint to a raw dict with `target=None`, modify the structure accordingly, and then deserialize it back to the original target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "051e7a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': CustomTrainState(step=1, apply_fn=<bound method Module.apply of Dense(\n",
       "     # attributes\n",
       "     features = 3\n",
       "     use_bias = True\n",
       "     dtype = None\n",
       "     param_dtype = float32\n",
       "     precision = None\n",
       "     kernel_init = init\n",
       "     bias_init = zeros\n",
       "     dot_general = None\n",
       "     dot_general_cls = None\n",
       " )>, params={'bias': array([-0.001, -0.001, -0.001], dtype=float32), 'kernel': array([[ 0.26048955, -0.61399287, -0.23458514],\n",
       "        [ 0.11050402, -0.8765793 ,  0.9800635 ],\n",
       "        [ 0.36260957,  0.18276349, -0.6856061 ],\n",
       "        [-0.8519373 , -0.6416717 , -0.4818122 ],\n",
       "        [-0.6886102 , -0.33987316, -0.05898903]], dtype=float32)}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x30df92b00>, update=<function chain.<locals>.update_fn at 0x30df92b90>), opt_state=(EmptyState(), EmptyState()), batch_stats=array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])),\n",
       " 'config': {'dimensions': array([5, 3])},\n",
       " 'data': [array([0.59902626, 0.2172144 , 2.4202902 , 0.03266738, 1.2164948 ],\n",
       "        dtype=float32)]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save using the legacy Flax `checkpoints` API.\n",
    "flax.config.update('flax_use_orbax_checkpointing', False)\n",
    "checkpoints.save_checkpoint(ckpt_dir='/tmp/flax_ckpt/flax-checkpointing',\n",
    "                            target=ckpt,\n",
    "                            step=5,\n",
    "                            overwrite=True,\n",
    "                            keep=2)\n",
    "\n",
    "# Pass no target to get a raw state dictionary first.\n",
    "raw_state_dict = checkpoints.restore_checkpoint('/tmp/flax_ckpt/flax-checkpointing', target=None, step=5)\n",
    "# Add/remove fields as needed.\n",
    "raw_state_dict['model']['batch_stats'] = np.flip(np.arange(10))\n",
    "# Restore the classes with correct target now\n",
    "flax.serialization.from_state_dict(custom_target, raw_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b39501",
   "metadata": {},
   "source": [
    "## Asynchronized checkpointing\n",
    "\n",
    "Checkpointing is I/O heavy, and if you have a large amount of data to save, it may be worthwhile to put it into a background thread, while continuing with your training.\n",
    "\n",
    "You can do this by creating an [`orbax.checkpoint.AsyncCheckpointer`](https://github.com/google/orbax/blob/main/orbax/checkpoint/async_checkpointer.py) in place of the `orbax.checkpoint.PyTreeCheckpointer`.\n",
    "\n",
    "Note: You should use the same `async_checkpointer` to handle all your async saves across your training steps, so that it can make sure that a previous async save is done before the next one begins. This enables bookkeeping, such as `keep` (the number of checkpoints) and `overwrite` to be consistent across steps.\n",
    "\n",
    "Whenever you want to explicitly wait until an async save is done, you can call `async_checkpointer.wait_until_finished()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85be68a6",
   "metadata": {
    "outputId": "aefce94c-8bae-4355-c142-05f2b61c39e2"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "jax.distributed.initialize() must be called before any JAX computations are executed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# `orbax.checkpoint.AsyncCheckpointer` needs some multi-process initialization, because it was\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# originally designed for multi-process large model checkpointing.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# For Python notebooks or other single-process settings, just set up with `num_processes=1`.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Refer to https://jax.readthedocs.io/en/latest/multi_process.html#initializing-the-cluster\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# for how to set it up in multi-process scenarios.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost:8889\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m async_checkpointer \u001b[38;5;241m=\u001b[39m orbax\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mAsyncCheckpointer(\n\u001b[1;32m      9\u001b[0m     orbax\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mPyTreeCheckpointHandler(), timeout_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save your job:\u001b[39;00m\n",
      "File \u001b[0;32m~/envs/py310/lib/python3.10/site-packages/jax/_src/distributed.py:174\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(coordinator_address, num_processes, process_id, local_device_ids, initialization_timeout)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initializes the JAX distributed system.\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03mCalling :func:`~jax.distributed.initialize` prepares JAX for execution on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124;03m>>> jax.distributed.initialize(coordinator_address='10.0.0.1:1234', num_processes=2, process_id=1)  # doctest: +SKIP\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xla_bridge\u001b[38;5;241m.\u001b[39mbackends_are_initialized():\n\u001b[0;32m--> 174\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjax.distributed.initialize() must be called before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many JAX computations are executed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    176\u001b[0m global_state\u001b[38;5;241m.\u001b[39minitialize(coordinator_address, num_processes, process_id,\n\u001b[1;32m    177\u001b[0m                         local_device_ids, initialization_timeout)\n\u001b[1;32m    178\u001b[0m atexit\u001b[38;5;241m.\u001b[39mregister(shutdown)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: jax.distributed.initialize() must be called before any JAX computations are executed."
     ]
    }
   ],
   "source": [
    "# `orbax.checkpoint.AsyncCheckpointer` needs some multi-process initialization, because it was\n",
    "# originally designed for multi-process large model checkpointing.\n",
    "# For Python notebooks or other single-process settings, just set up with `num_processes=1`.\n",
    "# Refer to https://jax.readthedocs.io/en/latest/multi_process.html#initializing-the-cluster\n",
    "# for how to set it up in multi-process scenarios.\n",
    "jax.distributed.initialize(\"localhost:8889\", num_processes=1, process_id=0)\n",
    "\n",
    "async_checkpointer = orbax.checkpoint.AsyncCheckpointer(\n",
    "    orbax.checkpoint.PyTreeCheckpointHandler(), timeout_secs=50)\n",
    "\n",
    "# Save your job:\n",
    "async_checkpointer.save('/tmp/flax_ckpt/orbax/single_save_async', ckpt, save_args=save_args)\n",
    "# ... Continue with your work...\n",
    "\n",
    "# ... Until a time when you want to wait until the save completes:\n",
    "async_checkpointer.wait_until_finished()  # Blocks until the checkpoint saving is completed.\n",
    "async_checkpointer.restore('/tmp/flax_ckpt/orbax/single_save_async', item=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e93db6",
   "metadata": {},
   "source": [
    "If you are using Orbax `CheckpointManager`, just pass in the async_checkpointer when initializing it. Then, in practice, call `async_checkpoint_manager.wait_until_finished()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af33b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_checkpoint_manager = orbax.checkpoint.CheckpointManager(\n",
    "    '/tmp/flax_ckpt/orbax/managed_async', async_checkpointer, options)\n",
    "async_checkpoint_manager.wait_until_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e03cd",
   "metadata": {},
   "source": [
    "## Multi-host/multi-process checkpointing\n",
    "\n",
    "JAX provides a few ways to scale up your code on multiple hosts at the same time. This usually happens when the number of devices (CPU/GPU/TPU) is so large that different devices are managed by different hosts (CPU). To get started on JAX in multi-process settings, check out [Using JAX in multi-host and multi-process environments](https://jax.readthedocs.io/en/latest/multi_process.html) and the [distributed array guide](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html).\n",
    "\n",
    "In the [Single Program Multi Data (SPMD)](https://jax.readthedocs.io/en/latest/glossary.html#term-SPMD) paradigm with JAX `jit`, a large multi-process array can have its data sharded across different devices. (Note that JAX `pjit` and `jit` have been merged into a single unified interface. To learn about compiling and executing JAX functions in multi-host or multi-core environments, refer to [this guide](https://jax.readthedocs.io/en/latest/notebooks/Distributed_arrays_and_automatic_parallelization.html) and the [jax.Array migration guide](https://jax.readthedocs.io/en/latest/jax_array_migration.html).) When a multi-process array is serialized, each host dumps its data shards to a single shared storage, such as a Google Cloud bucket.\n",
    "\n",
    "Orbax supports saving and loading pytrees with multi-process arrays in the same fashion as single-process pytrees. However, it's recommended to use the asynchronized [`orbax.AsyncCheckpointer`](https://github.com/google/orbax/blob/main/orbax/checkpoint/async_checkpointer.py) to save large multi-process arrays on another thread, so that you can perform computation alongside the saves. With pure Orbax, saving checkpoints in a multi-process context uses the same API as in a single-process context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ubdUvyMrhD-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.sharding import PartitionSpec, NamedSharding\n",
    "\n",
    "# Create an array sharded across multiple devices.\n",
    "mesh_shape = (4, 2)\n",
    "devices = np.asarray(jax.devices()).reshape(*mesh_shape)\n",
    "mesh = jax.sharding.Mesh(devices, ('x', 'y'))\n",
    "\n",
    "mp_array = jax.device_put(np.arange(8 * 2).reshape(8, 2),\n",
    "                          NamedSharding(mesh, PartitionSpec('x', 'y')))\n",
    "\n",
    "# Make it a pytree.\n",
    "mp_ckpt = {'model': mp_array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "async_checkpoint_manager.save(0, mp_ckpt)\n",
    "async_checkpoint_manager.wait_until_finished()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4deee32e",
   "metadata": {},
   "source": [
    "When restoring a checkpoint with multi-process arrays, you need to specify what `sharding` each array should be restored back to. Otherwise, they will be restored as large `np.array`s on process 0, costing time and memory.\n",
    "\n",
    "(In this notebook, since we are on single-process, it will be restored as `np.array` even if we provide shardings.)\n",
    "\n",
    "### With Orbax\n",
    "\n",
    "Orbax allows you to specify this by passing a pytree of `sharding`s in `restore_args`. If you already have a reference pytree that has all the arrays with the right sharding, you can use `orbax_utils.restore_args_from_target` to transform it into the `restore_args` that Orbax needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7daaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reference doesn't need to be as large as your checkpoint!\n",
    "# Just make sure it has the `.sharding` you want.\n",
    "mp_smaller = jax.device_put(np.arange(8).reshape(4, 2),\n",
    "                            NamedSharding(mesh, PartitionSpec('x', 'y')))\n",
    "ref_ckpt = {'model': mp_smaller}\n",
    "\n",
    "restore_args = orbax_utils.restore_args_from_target(ref_ckpt)\n",
    "async_checkpoint_manager.restore(\n",
    "    0, items=ref_ckpt, restore_kwargs={'restore_args': restore_args})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc355ce",
   "metadata": {},
   "source": [
    "### With the legacy Flax: use `save_checkpoint_multiprocess`\n",
    "\n",
    "In legacy Flax, to save multi-process arrays, use [`flax.training.checkpoints.save_checkpoint_multiprocess()`](https://flax.readthedocs.io/en/latest/api_reference/flax.training.html#flax.training.checkpoints.save_checkpoint_multiprocess) in place of `save_checkpoint()` and with the same arguments.\n",
    "\n",
    "If your checkpoint is too large, you can specify `timeout_secs` in the manager and give it more time to finish writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d10039b",
   "metadata": {
    "outputId": "901bb097-0899-479d-b9ae-61dae79e7057"
   },
   "outputs": [],
   "source": [
    "async_checkpointer = orbax.checkpoint.AsyncCheckpointer(orbax.checkpoint.PyTreeCheckpointHandler(), timeout_secs=50)\n",
    "checkpoints.save_checkpoint_multiprocess(ckpt_dir,\n",
    "                                         mp_ckpt,\n",
    "                                         step=3,\n",
    "                                         overwrite=True,\n",
    "                                         keep=4,\n",
    "                                         orbax_checkpointer=async_checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9724c",
   "metadata": {
    "outputId": "393c4a0e-8a8c-4ca6-c609-93c8bab38e75"
   },
   "outputs": [],
   "source": [
    "mp_restored = checkpoints.restore_checkpoint(ckpt_dir,\n",
    "                                             target=ref_ckpt,\n",
    "                                             step=3,\n",
    "                                             orbax_checkpointer=async_checkpointer)\n",
    "mp_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cfdd59",
   "metadata": {},
   "source": [
    "## Orbax-as-backend troubleshooting\n",
    "\n",
    "As an intermediate stage of the migration (to Orbax from the legacy Flax `checkpoints` API), `flax.training.checkpoints` APIs will start to use Orbax as their backend when saving checkpoints starting from May 15, 2023.\n",
    "\n",
    "Checkpoints saved with the Orbax backend can be readable by either `flax.training.checkpoints.restore_checkpoint` or `orbax.checkpoint.PyTreeCheckpointer`.\n",
    "\n",
    "Code-wise, this is equivalent to setting the config flag [`flax.config.flax_use_orbax_checkpointing`](https://github.com/google/flax/blob/main/flax/configurations.py#L103) default to `True`. You can overwrite this value in your project with `flax.config.update('flax_use_orbax_checkpointing', <BoolValue>)` at any time.\n",
    "\n",
    "In general, this automatic migration will not affect most users. However, you may encounter issues if your API usage follows some specific pattern. Check out the sections below for troubleshooting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bceb1",
   "metadata": {},
   "source": [
    "### If your devices hang when writing checkpoints\n",
    "\n",
    "If you are running in a multi-host environment (usually anything larger than 8 TPU devices) and your devices hang when writing checkpoints, check if your code is in the following pattern (that is, the `save_checkpoint` only ran on host `0`):\n",
    "\n",
    "```\n",
    "if jax.process_index() == 0:\n",
    "  flax.training.checkpoints.save_checkpoint(...)\n",
    "```\n",
    "\n",
    "Unfortunately this is a legacy pattern that will be deprecated and won't be supported, because in a multi-process environment, the checkpointing code should coordinate among hosts instead of being triggered only on the host `0`. Replacing the code above with the following should resolve the hang issue:\n",
    "\n",
    "```\n",
    "flax.training.checkpoints.save_checkpoint_multiprocess(...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0ebb3",
   "metadata": {},
   "source": [
    "### If you don't save pytrees\n",
    "\n",
    "Orbax uses `orbax.checkpoint.PyTreeCheckpointHandler` to save checkpoints, which means they only save pytrees.\n",
    "\n",
    "If you want to save singular arrays or numbers, you have two options:\n",
    "\n",
    "1. Use `orbax.ArrayCheckpointHandler` to save them following [this migration section](https://flax.readthedocs.io/en/latest/guides/converting_and_upgrading/orbax_upgrade_guide.html#saving-loading-a-single-jax-or-numpy-array).\n",
    "\n",
    "1. Wrap it inside a pytree and save as usual."
   ]
  }
 ],
 "metadata": {
  "gpuClass": "standard",
  "jupytext": {
   "formats": "ipynb,md",
   "main_language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
